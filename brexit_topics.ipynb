{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from processing import computeWordCount\n",
    "import codecs\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import os\n",
    "from twitter.Tweet import Tweet\n",
    "from util import ngrams\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_pre = \"/home/muntean/brexit-enriched/all-brexit-with-sent_pre-lines.json\"\n",
    "filename_post = \"/home/muntean/brexit-enriched/all-brexit-with-sent_post-lines.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_tweetsAsTokens = Tweet.getTweetAsTweetTextTokensNoGZ(filename_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing tweets:  10000\n",
      "processing tweets:  20000\n",
      "processing tweets:  30000\n",
      "processing tweets:  40000\n",
      "processing tweets:  50000\n",
      "processing tweets:  60000\n",
      "processing tweets:  70000\n",
      "processing tweets:  80000\n",
      "processing tweets:  90000\n",
      "processing tweets:  100000\n",
      "processing tweets:  110000\n",
      "processing tweets:  120000\n",
      "processing tweets:  130000\n",
      "processing tweets:  140000\n",
      "processing tweets:  150000\n",
      "processing tweets:  160000\n",
      "processing tweets:  170000\n",
      "processing tweets:  180000\n",
      "processing tweets:  190000\n",
      "processing tweets:  200000\n",
      "processing tweets:  210000\n",
      "processing tweets:  220000\n",
      "processing tweets:  230000\n",
      "Total words 640407\n"
     ]
    }
   ],
   "source": [
    "sorted_pre_wordcount = computeWordCount.wordcountPlain(pre_tweetsAsTokens, False, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordcountPlain(tweets, onlyHashtags=False, ngram=1):\n",
    "    wordcount = defaultdict(int)\n",
    "\n",
    "    i = 0\n",
    "    for tweet in tweets:\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print 'processing tweets: ', i\n",
    "        tokenList = [t for t in tweet if (len(t) > 2 and (not ngrams.is_url_or_mention(t)))]\n",
    "        ngramsList = []\n",
    "        if ngram > 1:\n",
    "            for ng in range(1, ngram):\n",
    "#                 tokenList = tokenList + [ntoken for ntoken in ngrams.window_no_twitter_elems(tweet, ng + 1)]\n",
    "                ngramsList = ngramsList + [ntoken for ntoken in ngrams.window_no_twitter_elems(tweet, ng + 1)]\n",
    "\n",
    "        for token in ngramsList:  # len(token) > 2\n",
    "            if onlyHashtags:\n",
    "                if token.startswith('#'):\n",
    "                    wordcount[token] += 1\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                wordcount[token] += 1\n",
    "    print \"Total words\", len(wordcount)\n",
    "    sorted_wc = sorted(wordcount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_tweetsAsTokens = Tweet.getTweetAsTweetTextTokensNoGZ(filename_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing tweets:  10000\n",
      "processing tweets:  20000\n",
      "processing tweets:  30000\n",
      "processing tweets:  40000\n",
      "processing tweets:  50000\n",
      "processing tweets:  60000\n",
      "processing tweets:  70000\n",
      "processing tweets:  80000\n",
      "processing tweets:  90000\n",
      "processing tweets:  100000\n",
      "processing tweets:  110000\n",
      "processing tweets:  120000\n",
      "processing tweets:  130000\n",
      "processing tweets:  140000\n",
      "processing tweets:  150000\n",
      "processing tweets:  160000\n",
      "processing tweets:  170000\n",
      "processing tweets:  180000\n",
      "processing tweets:  190000\n",
      "processing tweets:  200000\n",
      "processing tweets:  210000\n",
      "processing tweets:  220000\n",
      "processing tweets:  230000\n",
      "Total words 1846765\n"
     ]
    }
   ],
   "source": [
    "sorted_pre_wordcount_no_uni = wordcountPlain(pre_tweetsAsTokens, False, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeWordCount.printUTF8(sorted_pre_wordcount_no_uni, \"/home/muntean/brexit-enriched/pre-brexit-topics-4grams.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_tweetsAsTokens = Tweet.getTweetAsTweetTextTokensNoGZ(filename_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing tweets:  10000\n",
      "processing tweets:  20000\n",
      "processing tweets:  30000\n",
      "processing tweets:  40000\n",
      "processing tweets:  50000\n",
      "processing tweets:  60000\n",
      "processing tweets:  70000\n",
      "processing tweets:  80000\n",
      "processing tweets:  90000\n",
      "processing tweets:  100000\n",
      "processing tweets:  110000\n",
      "processing tweets:  120000\n",
      "processing tweets:  130000\n",
      "processing tweets:  140000\n",
      "processing tweets:  150000\n",
      "processing tweets:  160000\n",
      "processing tweets:  170000\n",
      "processing tweets:  180000\n",
      "processing tweets:  190000\n",
      "processing tweets:  200000\n",
      "processing tweets:  210000\n",
      "processing tweets:  220000\n",
      "processing tweets:  230000\n",
      "processing tweets:  240000\n",
      "processing tweets:  250000\n",
      "processing tweets:  260000\n",
      "processing tweets:  270000\n",
      "processing tweets:  280000\n",
      "processing tweets:  290000\n",
      "processing tweets:  300000\n",
      "processing tweets:  310000\n",
      "processing tweets:  320000\n",
      "processing tweets:  330000\n",
      "processing tweets:  340000\n",
      "processing tweets:  350000\n",
      "processing tweets:  360000\n",
      "processing tweets:  370000\n",
      "processing tweets:  380000\n",
      "processing tweets:  390000\n",
      "processing tweets:  400000\n",
      "processing tweets:  410000\n",
      "processing tweets:  420000\n",
      "processing tweets:  430000\n",
      "processing tweets:  440000\n",
      "processing tweets:  450000\n",
      "processing tweets:  460000\n",
      "processing tweets:  470000\n",
      "processing tweets:  480000\n",
      "processing tweets:  490000\n",
      "processing tweets:  500000\n",
      "processing tweets:  510000\n",
      "processing tweets:  520000\n",
      "processing tweets:  530000\n",
      "processing tweets:  540000\n",
      "processing tweets:  550000\n",
      "processing tweets:  560000\n",
      "processing tweets:  570000\n",
      "processing tweets:  580000\n",
      "processing tweets:  590000\n",
      "processing tweets:  600000\n",
      "processing tweets:  610000\n",
      "processing tweets:  620000\n",
      "processing tweets:  630000\n",
      "processing tweets:  640000\n",
      "processing tweets:  650000\n",
      "processing tweets:  660000\n",
      "processing tweets:  670000\n",
      "processing tweets:  680000\n",
      "processing tweets:  690000\n",
      "processing tweets:  700000\n",
      "processing tweets:  710000\n",
      "processing tweets:  720000\n",
      "processing tweets:  730000\n",
      "processing tweets:  740000\n",
      "processing tweets:  750000\n",
      "processing tweets:  760000\n",
      "processing tweets:  770000\n",
      "processing tweets:  780000\n",
      "processing tweets:  790000\n",
      "processing tweets:  800000\n",
      "processing tweets:  810000\n",
      "processing tweets:  820000\n",
      "processing tweets:  830000\n",
      "processing tweets:  840000\n",
      "processing tweets:  850000\n",
      "processing tweets:  860000\n",
      "processing tweets:  870000\n",
      "processing tweets:  880000\n",
      "processing tweets:  890000\n",
      "processing tweets:  900000\n",
      "processing tweets:  910000\n",
      "processing tweets:  920000\n",
      "processing tweets:  930000\n",
      "processing tweets:  940000\n",
      "processing tweets:  950000\n",
      "processing tweets:  960000\n",
      "Total words 6672653\n"
     ]
    }
   ],
   "source": [
    "sorted_post_wordcount_no_uni = wordcountPlain(post_tweetsAsTokens, False, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computeWordCount.printUTF8(sorted_post_wordcount_no_uni, \"/home/muntean/brexit-enriched/post-brexit-topics-4grams.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
